{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478fa5b9",
   "metadata": {},
   "source": [
    "# Amazon Book Review Classification with BERT\n",
    "\n",
    "In this notebook, a binary classification model is trained and fined tuned using BERT on an Amazon Book Review dataset to predict whether a review is positive or negative.\n",
    "\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 - Preprocessing Data](#2)\n",
    "  - [ 2.1 Loading and Visualizing the Data](#2.1)\n",
    "  - [ 2.2 Preprocessing](#2.2)\n",
    "  - [ 2.3  Text Processing](#2.3)\n",
    "  - [ 2.4 Data Split](#2.4)\n",
    "- [ 3 - Classification Model](#3)\n",
    "  - [ 3.1 BERT Model](#3.1)\n",
    "  - [ 3.2 Training](#3.2)\n",
    "- [ 4 - Results](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c6ecd",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages \n",
    "\n",
    "Below are all the needed packages for this notebook.\n",
    "- [numpy](https://www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [pandas](https://pandas.pydata.org) is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool.\n",
    "- [tensorflow](https://www.tensorflow.org/) is an end-to-end machine learning platform.\n",
    "- [scikit-learn](https://scikit-learn.org/stable/) is a library of simple and efficient tools for predictive data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee26b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed0f6a",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Preprocessing Data\n",
    "\n",
    "The dataset for the model we'll build contains information about 3M book reviews for 212404 unique books and users that provided the review for each book.\n",
    "The dataset can be found here: [Amazon Book Reviews](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?utm_source=pocket_mylist)\n",
    "<br/><br/>\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 Loading and Visualizing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22d1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "data = pd.read_csv(\"./Data/Books_rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fee1c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
       "\n",
       "                          profileName review/helpfulness  review/score  \\\n",
       "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
       "1                       Kevin Killian              10/10           5.0   \n",
       "2                        John Granger              10/11           5.0   \n",
       "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
       "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
       "\n",
       "   review/time                                   review/summary  \\\n",
       "0    940636800           Nice collection of Julie Strain images   \n",
       "1   1095724800                                Really Enjoyed It   \n",
       "2   1078790400  Essential for every personal and Public Library   \n",
       "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4   1107993600                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2379335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape(rows, columns): (3000000, 10)\n",
      "\n",
      "review/score values: [4.0, 5.0, 1.0, 3.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape(rows, columns): {data.shape}\\n\")\n",
    "print(f\"review/score values: {data['review/score'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc21c89",
   "metadata": {},
   "source": [
    "<a name=\"2.2\"></a>\n",
    "### 2.2 Preprocessing\n",
    "\n",
    "We can see we have 3 million items with 10 columns, and the review score for the books is on a range from 1 to 5. We want to train a binary model, so lets examine some of the reviews with a rating in the middle more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc490717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>B0007FIF28</td>\n",
       "      <td>The Overbury affair (Avon)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2GERYVE64DIPL</td>\n",
       "      <td>lisamac</td>\n",
       "      <td>0/0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1313366400</td>\n",
       "      <td>Overbury</td>\n",
       "      <td>Full of intrigue and a good overview of the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1858683092</td>\n",
       "      <td>Mensa Number Puzzles (Mensa Word Games for Kids)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1AYN4J7T43M11</td>\n",
       "      <td>\"dirtpile\"</td>\n",
       "      <td>4/4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>981417600</td>\n",
       "      <td>Made me wish I was Einstein.</td>\n",
       "      <td>Not much I can say about this book... It's ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0792391810</td>\n",
       "      <td>Vector Quantization and Signal Compression (Th...</td>\n",
       "      <td>76.94</td>\n",
       "      <td>A30DX2BO4Y4NLU</td>\n",
       "      <td>Moosh</td>\n",
       "      <td>3/5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1113609600</td>\n",
       "      <td>Comprehensive but marred by poor printing</td>\n",
       "      <td>This book appears to be a \"print on demand\" st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0974289108</td>\n",
       "      <td>The Ultimate Guide to Law School Admission: In...</td>\n",
       "      <td>14.95</td>\n",
       "      <td>A1KZ0RDJZQSY4O</td>\n",
       "      <td>sayock</td>\n",
       "      <td>27/29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1090368000</td>\n",
       "      <td>No &amp;quot;Insider&amp;quot; Secrets</td>\n",
       "      <td>If you are someone who is fairly new to the la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>B000NKGYMK</td>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A258YNWJW2264M</td>\n",
       "      <td>Tessa F. Briggs \"Tessa B\"</td>\n",
       "      <td>8/14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1241827200</td>\n",
       "      <td>Not your quick refrence cookbook</td>\n",
       "      <td>After having a chance to read through the book...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id                                              Title  Price  \\\n",
       "51   B0007FIF28                         The Overbury affair (Avon)    NaN   \n",
       "72   1858683092   Mensa Number Puzzles (Mensa Word Games for Kids)    NaN   \n",
       "76   0792391810  Vector Quantization and Signal Compression (Th...  76.94   \n",
       "81   0974289108  The Ultimate Guide to Law School Admission: In...  14.95   \n",
       "105  B000NKGYMK                                   Alaska Sourdough    NaN   \n",
       "\n",
       "            User_id                profileName review/helpfulness  \\\n",
       "51   A2GERYVE64DIPL                    lisamac                0/0   \n",
       "72   A1AYN4J7T43M11                 \"dirtpile\"                4/4   \n",
       "76   A30DX2BO4Y4NLU                      Moosh                3/5   \n",
       "81   A1KZ0RDJZQSY4O                     sayock              27/29   \n",
       "105  A258YNWJW2264M  Tessa F. Briggs \"Tessa B\"               8/14   \n",
       "\n",
       "     review/score  review/time                             review/summary  \\\n",
       "51            3.0   1313366400                                   Overbury   \n",
       "72            3.0    981417600               Made me wish I was Einstein.   \n",
       "76            3.0   1113609600  Comprehensive but marred by poor printing   \n",
       "81            3.0   1090368000             No &quot;Insider&quot; Secrets   \n",
       "105           3.0   1241827200           Not your quick refrence cookbook   \n",
       "\n",
       "                                           review/text  \n",
       "51   Full of intrigue and a good overview of the co...  \n",
       "72   Not much I can say about this book... It's ful...  \n",
       "76   This book appears to be a \"print on demand\" st...  \n",
       "81   If you are someone who is fairly new to the la...  \n",
       "105  After having a chance to read through the book...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get dataframe with rows that have only 3 as score value\n",
    "trees = data.loc[data['review/score'] == 3.0]\n",
    "trees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7a90c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: Full of intrigue and a good overview of the court of James 1 and the key players. Provides a good general history of all the facts of the case.\n",
      "\n",
      "Review 2: Not much I can say about this book... It's full of VVVery difficult number puzzles... at least for me. Okay, so I don't get 'A's for my grades at school, but I think that even you might find it a little difficult. The way I see it, you will need lots of paper, patience and time, say 30 minutes or so to solve even the easiest of these.Why? Because basically, you are asked how many combinations can be formed from such and such. Example: How many ways get 31241 by adding prime numbers only? This is not really what the problems are like in the book, they are far more complicated than that.For me, it's just too much. I can't even do 1 single problem. I can't even look up the answers because uses some sort of a legend that I can't understand. But if you have an above average intelligence or are mathematically gifted, you will probably find some obscure short cut to the problem a la Gauss. For the rest, forget it.Word of warning: these are purely number problems. I can't tell if logic will help or even plays a part in this book, but the problems are NUMBER problems.\n",
      "\n",
      "Review 3: This book appears to be a \"print on demand\" style book which manifests itself, in this case, as a poor quality hardcover. Some of the text is laughably bad, the few images near the end look like they are snapshots from a black and white TV screen, but most bothersome is the \"muddy\" look of the text. The price seems a bit steep for such a poor quality print. That said, the actual content is very comprehensive. One of the authors (Gray) is co-creator of the now commonplace LBG (Linde Buzo Gray) VQ algorithm. Fortunately, the quality of the content shines through the terrible printing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review 1: {trees['review/text'].iloc[0]}\\n\")\n",
    "print(f\"Review 2: {trees['review/text'].iloc[1]}\\n\")\n",
    "print(f\"Review 3: {trees['review/text'].iloc[2]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31584e",
   "metadata": {},
   "source": [
    "We can see the reviews with a rating of 3 can be either postive or negative, or even both. We'll exclude the score reviews with a value of 3, as we'll want to train our model with clear negative/positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc84bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of original dataframe\n",
    "df = data.copy()\n",
    "\n",
    "#Rename columns for simplicity\n",
    "df.rename(columns = {'review/text':'text'}, inplace = True)\n",
    "df.rename(columns = {'review/score':'score'}, inplace = True)\n",
    "df.rename(columns = {'review/summary':'summary'}, inplace = True)\n",
    "\n",
    "#Datarame without rows with 3 as score value\n",
    "df = df[df.score != 3.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b9f01",
   "metadata": {},
   "source": [
    "Lets drop the unecessary columns. For our training data, we'll only need the score and text columns. The summary will also be kept for now as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8c5b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                          summary  \\\n",
       "0    4.0           Nice collection of Julie Strain images   \n",
       "1    5.0                                Really Enjoyed It   \n",
       "2    5.0  Essential for every personal and Public Library   \n",
       "3    4.0  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4    4.0                           Good academic overview   \n",
       "\n",
       "                                                text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/time'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c30471",
   "metadata": {},
   "source": [
    "Lets also check for missing values and get rid of those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516c5eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score       0\n",
       "summary    36\n",
       "text        8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095103fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows: 2745705\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d749c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score       0\n",
       "summary    36\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe without null values in text\n",
    "df = df[df['text'].notna()]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58239d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows: 2745697\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df27e3",
   "metadata": {},
   "source": [
    "Now lets transform the score variable into binary values. For this we'll assign a value of 0 to scores 1.0 and 2.0, and a value of 1 to 4.0 and 5.0. A score of 0 being a negative review and 1 a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                          summary  \\\n",
       "0      1           Nice collection of Julie Strain images   \n",
       "1      1                                Really Enjoyed It   \n",
       "2      1  Essential for every personal and Public Library   \n",
       "3      1  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4      1                           Good academic overview   \n",
       "\n",
       "                                                text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change score values to binary\n",
    "classes = {1.0: 0, 2.0: 0, 4.0: 1, 5.0: 1}\n",
    "df['score'] = df['score'].map(classes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b8a673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2392951\n",
       "0     352746\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of rows per value\n",
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e4c83",
   "metadata": {},
   "source": [
    "The dataset is highly unbalanced, so we'll have to reduce the number of positive reviews to match those of negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fc0bdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    352746\n",
       "0    352746\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute difference by value and balance dataset\n",
    "pos = df['score'].value_counts()[1]\n",
    "neg = df['score'].value_counts()[0]\n",
    "df.drop(df[df.score == 1].index[-(pos-neg):], inplace=True)\n",
    "df.score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349947b4",
   "metadata": {},
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3 Text Processing\n",
    "\n",
    "Now we can process and clean the text itself. For this, lets remove unecessary vocabulary like stopwords and single characters, as well as punctuation and numbers.\n",
    "\n",
    "Stopwords are unecessary words that will be of no use as keywords, such as: about, are, at, because, does, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e5ff7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_punct(text):\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_nums(text):\n",
    "    translator = str.maketrans(\"\", \"\", \"0123456789\")\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_single_char(text):\n",
    "    threshold = 1\n",
    "    filtered_words =[word for word in text.split() if len(word) > threshold]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d6efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process text\n",
    "df['text'] = df.text.map(remove_punct)\n",
    "df['text'] = df.text.map(remove_nums)\n",
    "df['text'] = df.text.map(remove_single_char)\n",
    "df['text'] = df.text.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d09ae",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 Data Split\n",
    "\n",
    "The dataset is now ready. Before we define our model, lets get our our x and y arrays from the dataframe, and split them into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6336cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert pandas dataframe to numpy array\n",
    "x = df.text.to_numpy() #text column\n",
    "y = df.score.to_numpy() #score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efeff89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa474b75",
   "metadata": {},
   "source": [
    "The validation set will be 30% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "825c2654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y values\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43499b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length: 493844\n",
      "validation length: 211648\n"
     ]
    }
   ],
   "source": [
    "print(f\"train length: {len(train_x)}\")\n",
    "print(f\"validation length: {len(val_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855cfc3",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Classification Model\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 BERT Model\n",
    "\n",
    "Bert processor and encoder from tensorflow_hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4253c61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "#Load BERT model preprocessor and encoder\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb2312",
   "metadata": {},
   "source": [
    "The model will be a functional model and will include a dropout layer to reduce overfitting and an output Dense layer with a sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f649ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build functional model\n",
    "text_input = Input(shape=(), dtype=tf.string, name=\"text\")\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "l = Dropout(0.3, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5b40191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'encoder_outputs':  109482241   ['keras_layer[0][0]',            \n",
      "                                 [(None, 128, 768),               'keras_layer[0][1]',            \n",
      "                                 (None, 128, 768),                'keras_layer[0][2]']            \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f2ce1",
   "metadata": {},
   "source": [
    "<a name=\"3.2\"></a>\n",
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16a53cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15433/15433 [==============================] - 2604s 168ms/step - loss: 0.5748 - accuracy: 0.7003 - val_loss: 0.5183 - val_accuracy: 0.7548\n",
      "Epoch 2/3\n",
      "15433/15433 [==============================] - 2523s 163ms/step - loss: 0.5638 - accuracy: 0.7107 - val_loss: 0.5219 - val_accuracy: 0.7485\n",
      "Epoch 3/3\n",
      "15433/15433 [==============================] - 2504s 162ms/step - loss: 0.5645 - accuracy: 0.7101 - val_loss: 0.5178 - val_accuracy: 0.7530\n"
     ]
    }
   ],
   "source": [
    "#Configure and train\n",
    "model.compile(\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size = 32,\n",
    "    validation_data = (val_x, val_y),\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb88eb",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Results\n",
    "\n",
    "The results of the loss function and accuracy for both of the training data and the validation data is close, this means the model is not overfitting and can be used for generalization and predictions. With a loss function of 0.56 and an accuracy of 0.71 for the training data, and a loss function of 0.52 and accuracy of 0.75 for the validation data, we have a good model for this data. Data augementation, along with other models could be implemented to elicit better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
